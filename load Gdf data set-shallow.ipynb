{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a638ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63e1e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "all_file_path = glob.glob('BCICIV 2a/*.gdf')\n",
    "print(len(all_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ddaf893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n"
     ]
    }
   ],
   "source": [
    "train_file_path = [i for i in all_file_path if 'T' in i.split('\\\\', 1)[-1]]\n",
    "eval_file_path = [i for i in all_file_path if 'E' in i.split('\\\\', 1)[-1]]\n",
    "print(len(train_file_path),len(eval_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db07729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the function of data generating and filterring\n",
    "def read_data(file_path):\n",
    "    data = mne.io.read_raw_gdf(file_path, preload = True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(0.5, 100, method='iir')\n",
    "    # Set EOG channel types\n",
    "    eog_channels = ['EOG-left', 'EOG-central', 'EOG-right']\n",
    "    for ch_name in eog_channels:\n",
    "        if ch_name in data.ch_names:\n",
    "            data.set_channel_types({ch_name: 'eog'})\n",
    "\n",
    "    # Pick EEG and EOG channels\n",
    "    picks = mne.pick_types(data.info, meg=False, eeg=True, eog=False, stim=False,\n",
    "                       exclude=[])\n",
    "    events, event_id = mne.events_from_annotations(data)\n",
    "    selected_event_labels = ['769', '770', '771', '772']\n",
    "    selected_event_id = {label: event_id[label] for label in selected_event_labels}\n",
    "\n",
    "    # Filter the events array\n",
    "    selected_events = events[np.isin(events[:, 2], list(selected_event_id.values()))]\n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(data, selected_events, selected_event_id, tmin = -0., tmax = 1, proj=False, \n",
    "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
    "    labels = epochs.events[:, -1]\n",
    "    # extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "    X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
    "    Y = labels\n",
    "    return X\n",
    "def read_labels(file_path):\n",
    "    data = mne.io.read_raw_gdf(file_path, preload = True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(0.5, 100, method='iir')\n",
    "    # Set EOG channel types\n",
    "    eog_channels = ['EOG-left', 'EOG-central', 'EOG-right']\n",
    "    for ch_name in eog_channels:\n",
    "        if ch_name in data.ch_names:\n",
    "            data.set_channel_types({ch_name: 'eog'})\n",
    "\n",
    "    # Pick EEG and EOG channels\n",
    "    picks = mne.pick_types(data.info, meg=False, eeg=True, eog=False, stim=False,\n",
    "                       exclude=[])\n",
    "    events, event_id = mne.events_from_annotations(data)\n",
    "    selected_event_labels = ['769', '770', '771', '772']\n",
    "    selected_event_id = {label: event_id[label] for label in selected_event_labels}\n",
    "\n",
    "    # Filter the events array\n",
    "    selected_events = events[np.isin(events[:, 2], list(selected_event_id.values()))]\n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(data, selected_events, selected_event_id, tmin = -0., tmax = 1, proj=False, \n",
    "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
    "    labels = epochs.events[:, -1]\n",
    "    # extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "    X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
    "    Y = labels\n",
    "    Y -= 6\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eec1bbd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/mitchell/Downloads/Trained Models/BCICIV 2a/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchell/anaconda3/envs/bci_test/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 1e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 100.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from /Users/mitchell/Downloads/Trained Models/BCICIV 2a/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchell/anaconda3/envs/bci_test/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 1e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 100.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    }
   ],
   "source": [
    "X = read_data(train_file_path[0])\n",
    "Y = read_labels(train_file_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62265561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e853616",
   "metadata": {},
   "outputs": [],
   "source": [
    "chans, samples = 22, 251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ba1882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 50/25/25 percent of the data to train/validate/test\n",
    "X_train      = X[0:144,]\n",
    "Y_train      = Y[0:144]\n",
    "X_validate   = X[144:216,]\n",
    "Y_validate   = Y[144:216]\n",
    "X_test       = X[216:,]\n",
    "Y_test       = Y[216:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4b922a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# convert labels to one-hot encodings.\n",
    "Y_train      = to_categorical(Y_train-1)\n",
    "Y_validate   = to_categorical(Y_validate-1)\n",
    "Y_test       = to_categorical(Y_test-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e0bdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to NHWC (trials, channels, samples, kernels) format. Data \n",
    "# contains 22 channels and 251 time-points.\n",
    "X_train      = X_train.reshape(X_train.shape[0], chans, samples)\n",
    "X_validate   = X_validate.reshape(X_validate.shape[0], chans, samples)\n",
    "X_test       = X_test.reshape(X_test.shape[0], chans, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57ecdcd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (144, 22, 251)\n",
      "[[ 0.00718636  0.00910629  0.01217317 ... -0.00546961 -0.005243\n",
      "  -0.00408977]\n",
      " [ 0.00182106  0.00303724  0.00355259 ... -0.00215978 -0.00515362\n",
      "  -0.00557592]\n",
      " [ 0.00220968  0.004249    0.00623719 ... -0.0064771  -0.006795\n",
      "  -0.00680417]\n",
      " ...\n",
      " [ 0.00065093 -0.00138428 -0.00151616 ...  0.00540202  0.00486136\n",
      "   0.001413  ]\n",
      " [ 0.00084465 -0.00178895 -0.00325722 ...  0.00542044  0.00592322\n",
      "   0.0026308 ]\n",
      " [ 0.00387408  0.00077742  0.00087902 ...  0.00820446  0.0104787\n",
      "   0.00535328]]\n",
      "72 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train[0])\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "415d4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from CNNModels import ShallowConvNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8028711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 15:20:00.057335: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# configure the ShallowConvNet\n",
    "model = ShallowConvNet(nb_classes = 4, Chans = chans, Samples = samples, \n",
    "               dropoutRate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f97352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model and set the optimizers\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "533cd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal weights\n",
    "model.load_weights('./shallow model/checkpoint_SC.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbc48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint_SC.h5', verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18b91485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
    "# the weights all to be 1\n",
    "class_weights = {0:1, 1:1, 2:1, 3:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d4675fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 3.73417, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.7342 - val_accuracy: 0.2778 - 789ms/epoch - 88ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 3.73417\n",
      "9/9 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.7656 - val_accuracy: 0.2639 - 158ms/epoch - 18ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 3.73417 to 3.57619, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.5762 - val_accuracy: 0.2500 - 182ms/epoch - 20ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 3.57619\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.0770 - val_accuracy: 0.2778 - 163ms/epoch - 18ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 3.57619 to 2.81369, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.2639 - 186ms/epoch - 21ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 2.81369 to 2.18947, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1895 - val_accuracy: 0.4861 - 187ms/epoch - 21ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 2.18947 to 1.93267, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.9327 - val_accuracy: 0.3056 - 175ms/epoch - 19ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.93267\n",
      "9/9 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 7.0678 - val_accuracy: 0.2639 - 197ms/epoch - 22ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss improved from 1.93267 to 1.28601, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2860 - val_accuracy: 0.4444 - 183ms/epoch - 20ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.9233 - val_accuracy: 0.3194 - 157ms/epoch - 17ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8173 - val_accuracy: 0.2639 - 170ms/epoch - 19ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.3632 - val_accuracy: 0.4722 - 179ms/epoch - 20ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.3515 - val_accuracy: 0.3889 - 214ms/epoch - 24ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.4111 - val_accuracy: 0.2639 - 288ms/epoch - 32ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.7607 - val_accuracy: 0.2500 - 229ms/epoch - 25ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.9104 - val_accuracy: 0.2917 - 189ms/epoch - 21ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.5778 - val_accuracy: 0.2917 - 178ms/epoch - 20ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.9072 - val_accuracy: 0.2917 - 170ms/epoch - 19ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.8491 - val_accuracy: 0.3472 - 172ms/epoch - 19ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.5460 - val_accuracy: 0.3611 - 171ms/epoch - 19ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.2587 - val_accuracy: 0.2778 - 168ms/epoch - 19ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6876 - val_accuracy: 0.3194 - 158ms/epoch - 18ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.9560 - val_accuracy: 0.2222 - 171ms/epoch - 19ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 5.1473 - val_accuracy: 0.2639 - 184ms/epoch - 20ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 5.8689 - val_accuracy: 0.2500 - 181ms/epoch - 20ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.9631 - val_accuracy: 0.2361 - 195ms/epoch - 22ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.5729 - val_accuracy: 0.3056 - 251ms/epoch - 28ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 7.2269 - val_accuracy: 0.2222 - 206ms/epoch - 23ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 18.6487 - val_accuracy: 0.2639 - 172ms/epoch - 19ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 9.3984 - val_accuracy: 0.2639 - 178ms/epoch - 20ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 8.2041 - val_accuracy: 0.2639 - 159ms/epoch - 18ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 6.9527 - val_accuracy: 0.2639 - 186ms/epoch - 21ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 6.0920 - val_accuracy: 0.2639 - 182ms/epoch - 20ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 4.7619 - val_accuracy: 0.2639 - 174ms/epoch - 19ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0129 - val_accuracy: 0.2778 - 173ms/epoch - 19ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.28601\n",
      "9/9 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.9868 - val_accuracy: 0.3889 - 227ms/epoch - 25ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 1.28601 to 1.20267, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.4861 - 196ms/epoch - 22ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 1.20267 to 0.86579, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.6389 - 190ms/epoch - 21ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.86579\n",
      "9/9 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8710 - val_accuracy: 0.6528 - 167ms/epoch - 19ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.86579\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0949 - val_accuracy: 0.5833 - 156ms/epoch - 17ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.86579\n",
      "9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9315 - val_accuracy: 0.6667 - 157ms/epoch - 17ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 0.86579 to 0.82673, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8267 - val_accuracy: 0.6806 - 181ms/epoch - 20ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.82673\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 0.6806 - 155ms/epoch - 17ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.82673\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.6667 - 158ms/epoch - 18ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss improved from 0.82673 to 0.80711, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.6806 - 179ms/epoch - 20ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss improved from 0.80711 to 0.71830, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.7083 - 191ms/epoch - 21ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.71830\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0497 - val_accuracy: 0.5417 - 171ms/epoch - 19ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.71830\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.6908 - val_accuracy: 0.4028 - 169ms/epoch - 19ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.71830\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.5694 - 170ms/epoch - 19ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.71830\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.6111 - 168ms/epoch - 19ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.71830\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.6667 - 160ms/epoch - 18ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 0.71830 to 0.64955, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.6944 - 177ms/epoch - 20ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.64955\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.6806 - 157ms/epoch - 17ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.64955\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.7222 - 203ms/epoch - 23ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss improved from 0.64955 to 0.64286, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.7639 - 181ms/epoch - 20ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.7500 - 161ms/epoch - 18ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.6944 - 165ms/epoch - 18ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.7083 - 157ms/epoch - 17ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.6528 - 168ms/epoch - 19ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 0.7083 - 172ms/epoch - 19ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.7083 - 173ms/epoch - 19ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8468 - val_accuracy: 0.6667 - 171ms/epoch - 19ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.7361 - 158ms/epoch - 18ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9293 - val_accuracy: 0.6806 - 158ms/epoch - 18ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3358 - val_accuracy: 0.4722 - 158ms/epoch - 18ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.7222 - 159ms/epoch - 18ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.7222 - 158ms/epoch - 18ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.7639 - 159ms/epoch - 18ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.6111 - 164ms/epoch - 18ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.6250 - 164ms/epoch - 18ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8626 - val_accuracy: 0.6250 - 160ms/epoch - 18ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.6806 - 175ms/epoch - 19ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.6667 - 171ms/epoch - 19ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.6806 - 170ms/epoch - 19ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7773 - val_accuracy: 0.6389 - 167ms/epoch - 19ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.6944 - 158ms/epoch - 18ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.7222 - 169ms/epoch - 19ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8892 - val_accuracy: 0.6389 - 156ms/epoch - 17ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.6528 - 158ms/epoch - 18ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.64286\n",
      "9/9 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.6389 - 157ms/epoch - 17ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss improved from 0.64286 to 0.62596, saving model to /tmp/checkpoint_SC.h5\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.7083 - 175ms/epoch - 19ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.7083 - 170ms/epoch - 19ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.6667 - 173ms/epoch - 19ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.6944 - 170ms/epoch - 19ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9804 - val_accuracy: 0.5833 - 170ms/epoch - 19ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.6667 - 169ms/epoch - 19ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8719 - val_accuracy: 0.6389 - 158ms/epoch - 18ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.6389 - 158ms/epoch - 18ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.5972 - 158ms/epoch - 18ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.5139 - 160ms/epoch - 18ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5472 - val_accuracy: 0.3750 - 157ms/epoch - 17ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.7917 - 156ms/epoch - 17ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.6389 - 164ms/epoch - 18ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.6250 - 167ms/epoch - 19ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0721 - val_accuracy: 0.6111 - 171ms/epoch - 19ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.6389 - 184ms/epoch - 20ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8056 - 172ms/epoch - 19ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0710 - val_accuracy: 0.6389 - 164ms/epoch - 18ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1980 - val_accuracy: 0.5139 - 156ms/epoch - 17ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1983 - val_accuracy: 0.5000 - 158ms/epoch - 18ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.2639 - 159ms/epoch - 18ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.5417 - 158ms/epoch - 18ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8502 - val_accuracy: 0.6250 - 157ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3500 - val_accuracy: 0.4167 - 159ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5543 - val_accuracy: 0.4167 - 168ms/epoch - 19ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.5000 - 171ms/epoch - 19ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0575 - val_accuracy: 0.5972 - 194ms/epoch - 22ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.6389 - 188ms/epoch - 21ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.0531 - val_accuracy: 0.2361 - 197ms/epoch - 22ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3168 - val_accuracy: 0.4167 - 168ms/epoch - 19ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3634 - val_accuracy: 0.3889 - 171ms/epoch - 19ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.4722 - 171ms/epoch - 19ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3871 - val_accuracy: 0.3750 - 163ms/epoch - 18ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1638 - val_accuracy: 0.3611 - 155ms/epoch - 17ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.6561 - val_accuracy: 0.4028 - 158ms/epoch - 18ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.4569 - val_accuracy: 0.2639 - 167ms/epoch - 19ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.7648 - val_accuracy: 0.3056 - 156ms/epoch - 17ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8434 - val_accuracy: 0.2917 - 156ms/epoch - 17ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7503 - val_accuracy: 0.2639 - 167ms/epoch - 19ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.0320 - val_accuracy: 0.3056 - 171ms/epoch - 19ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.5300 - val_accuracy: 0.2778 - 169ms/epoch - 19ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.2104 - val_accuracy: 0.3472 - 169ms/epoch - 19ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4100 - val_accuracy: 0.4444 - 169ms/epoch - 19ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6232 - val_accuracy: 0.2639 - 156ms/epoch - 17ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.9584 - val_accuracy: 0.2917 - 157ms/epoch - 17ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7001 - val_accuracy: 0.3889 - 156ms/epoch - 17ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8575 - val_accuracy: 0.2222 - 158ms/epoch - 18ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.3546 - val_accuracy: 0.2361 - 154ms/epoch - 17ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4981 - val_accuracy: 0.3056 - 156ms/epoch - 17ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7634 - val_accuracy: 0.4028 - 166ms/epoch - 18ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8965 - val_accuracy: 0.2917 - 166ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1572 - val_accuracy: 0.3889 - 170ms/epoch - 19ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.4719 - val_accuracy: 0.2778 - 172ms/epoch - 19ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0267 - val_accuracy: 0.2639 - 169ms/epoch - 19ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1250 - val_accuracy: 0.3611 - 163ms/epoch - 18ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3875 - val_accuracy: 0.4167 - 156ms/epoch - 17ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3974 - val_accuracy: 0.3333 - 156ms/epoch - 17ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.4237 - val_accuracy: 0.3611 - 154ms/epoch - 17ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.7688 - val_accuracy: 0.2639 - 157ms/epoch - 17ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7357 - val_accuracy: 0.3611 - 155ms/epoch - 17ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.7925 - val_accuracy: 0.2361 - 157ms/epoch - 17ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.9489 - val_accuracy: 0.3472 - 169ms/epoch - 19ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.7504 - val_accuracy: 0.2778 - 185ms/epoch - 21ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.4417 - val_accuracy: 0.3611 - 170ms/epoch - 19ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.5256 - val_accuracy: 0.2778 - 170ms/epoch - 19ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.6563 - val_accuracy: 0.2639 - 185ms/epoch - 21ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.5104 - val_accuracy: 0.2639 - 162ms/epoch - 18ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.3194 - 156ms/epoch - 17ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9702 - val_accuracy: 0.3611 - 155ms/epoch - 17ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8474 - val_accuracy: 0.2639 - 155ms/epoch - 17ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 6.1588 - val_accuracy: 0.2639 - 156ms/epoch - 17ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.2258 - val_accuracy: 0.3611 - 156ms/epoch - 17ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8215 - val_accuracy: 0.2639 - 165ms/epoch - 18ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.9659 - val_accuracy: 0.2639 - 160ms/epoch - 18ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.2917 - 157ms/epoch - 17ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4024 - val_accuracy: 0.2639 - 167ms/epoch - 19ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.5698 - val_accuracy: 0.2639 - 167ms/epoch - 19ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.0984 - val_accuracy: 0.2500 - 170ms/epoch - 19ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.4124 - val_accuracy: 0.2222 - 168ms/epoch - 19ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.4476 - val_accuracy: 0.3194 - 158ms/epoch - 18ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4149 - val_accuracy: 0.2639 - 155ms/epoch - 17ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.0883 - val_accuracy: 0.3194 - 156ms/epoch - 17ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.0459 - val_accuracy: 0.3611 - 157ms/epoch - 17ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.6422 - val_accuracy: 0.2639 - 157ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9651 - val_accuracy: 0.2639 - 182ms/epoch - 20ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1977 - val_accuracy: 0.3056 - 177ms/epoch - 20ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.5344 - val_accuracy: 0.2639 - 169ms/epoch - 19ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.3914 - val_accuracy: 0.2778 - 171ms/epoch - 19ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4901 - val_accuracy: 0.4306 - 172ms/epoch - 19ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.5278 - 170ms/epoch - 19ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.3194 - 164ms/epoch - 18ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7363 - val_accuracy: 0.3472 - 158ms/epoch - 18ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6095 - val_accuracy: 0.3889 - 183ms/epoch - 20ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.5814 - val_accuracy: 0.2222 - 206ms/epoch - 23ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8014 - val_accuracy: 0.3194 - 175ms/epoch - 19ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.8804 - val_accuracy: 0.2639 - 173ms/epoch - 19ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.1106 - val_accuracy: 0.2639 - 191ms/epoch - 21ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.0206 - val_accuracy: 0.3056 - 164ms/epoch - 18ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.9638 - val_accuracy: 0.2500 - 176ms/epoch - 20ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 5.3168 - val_accuracy: 0.2639 - 170ms/epoch - 19ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.9810 - val_accuracy: 0.2639 - 169ms/epoch - 19ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 7.4221 - val_accuracy: 0.2639 - 179ms/epoch - 20ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.6422 - val_accuracy: 0.2639 - 177ms/epoch - 20ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 13.4838 - val_accuracy: 0.2639 - 158ms/epoch - 18ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 7.7082 - val_accuracy: 0.2083 - 162ms/epoch - 18ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 6.7658 - val_accuracy: 0.2639 - 159ms/epoch - 18ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.7947 - val_accuracy: 0.2917 - 169ms/epoch - 19ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 7.5904 - val_accuracy: 0.2639 - 157ms/epoch - 17ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.6985 - val_accuracy: 0.2361 - 169ms/epoch - 19ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.1820 - val_accuracy: 0.2500 - 158ms/epoch - 18ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8448 - val_accuracy: 0.2917 - 159ms/epoch - 18ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0073 - val_accuracy: 0.5000 - 170ms/epoch - 19ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.6918 - val_accuracy: 0.2361 - 166ms/epoch - 18ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.6102 - val_accuracy: 0.2361 - 169ms/epoch - 19ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.5128 - val_accuracy: 0.3750 - 169ms/epoch - 19ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.4362 - val_accuracy: 0.2778 - 162ms/epoch - 18ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.6896 - val_accuracy: 0.2917 - 156ms/epoch - 17ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.1015 - val_accuracy: 0.3194 - 157ms/epoch - 17ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6149 - val_accuracy: 0.2778 - 157ms/epoch - 17ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.7283 - val_accuracy: 0.2083 - 158ms/epoch - 18ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.5623 - val_accuracy: 0.3333 - 156ms/epoch - 17ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.4861 - 176ms/epoch - 20ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4755 - val_accuracy: 0.4583 - 185ms/epoch - 21ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.5278 - 188ms/epoch - 21ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4496 - val_accuracy: 0.2500 - 193ms/epoch - 21ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6337 - val_accuracy: 0.3333 - 205ms/epoch - 23ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9476 - val_accuracy: 0.3889 - 168ms/epoch - 19ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8066 - val_accuracy: 0.4167 - 174ms/epoch - 19ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.4722 - 164ms/epoch - 18ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4280 - val_accuracy: 0.5000 - 158ms/epoch - 18ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6049 - val_accuracy: 0.3333 - 156ms/epoch - 17ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.8376 - val_accuracy: 0.2917 - 155ms/epoch - 17ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.3136 - val_accuracy: 0.2222 - 168ms/epoch - 19ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6679 - val_accuracy: 0.3333 - 170ms/epoch - 19ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.5431 - val_accuracy: 0.2778 - 171ms/epoch - 19ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.8084 - val_accuracy: 0.2778 - 171ms/epoch - 19ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.2938 - val_accuracy: 0.2639 - 171ms/epoch - 19ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.9285 - val_accuracy: 0.3889 - 157ms/epoch - 17ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6135 - val_accuracy: 0.3472 - 158ms/epoch - 18ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5773 - val_accuracy: 0.2778 - 155ms/epoch - 17ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.9367 - val_accuracy: 0.2500 - 155ms/epoch - 17ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.5713 - val_accuracy: 0.2917 - 159ms/epoch - 18ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8351 - val_accuracy: 0.2639 - 170ms/epoch - 19ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.9783 - val_accuracy: 0.2917 - 163ms/epoch - 18ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.5354 - val_accuracy: 0.2778 - 179ms/epoch - 20ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.9826 - val_accuracy: 0.3194 - 169ms/epoch - 19ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.3474 - val_accuracy: 0.2917 - 169ms/epoch - 19ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 8.2412 - val_accuracy: 0.2639 - 170ms/epoch - 19ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7301 - val_accuracy: 0.2639 - 165ms/epoch - 18ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.3754 - val_accuracy: 0.3194 - 187ms/epoch - 21ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.2611 - val_accuracy: 0.2639 - 159ms/epoch - 18ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.1743 - val_accuracy: 0.2639 - 155ms/epoch - 17ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.2156 - val_accuracy: 0.2639 - 155ms/epoch - 17ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.3211 - val_accuracy: 0.2639 - 158ms/epoch - 18ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9102 - val_accuracy: 0.3889 - 158ms/epoch - 18ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.4069 - val_accuracy: 0.2639 - 167ms/epoch - 19ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.6796 - val_accuracy: 0.3750 - 172ms/epoch - 19ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.3194 - 171ms/epoch - 19ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.5000 - 181ms/epoch - 20ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6774 - val_accuracy: 0.3611 - 172ms/epoch - 19ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4470 - val_accuracy: 0.3194 - 159ms/epoch - 18ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.8439 - val_accuracy: 0.2778 - 157ms/epoch - 17ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.7401 - val_accuracy: 0.3056 - 157ms/epoch - 17ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.1025 - val_accuracy: 0.2639 - 158ms/epoch - 18ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.4132 - val_accuracy: 0.2639 - 159ms/epoch - 18ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1124 - val_accuracy: 0.3194 - 159ms/epoch - 18ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8526 - val_accuracy: 0.3194 - 165ms/epoch - 18ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 6.8104 - val_accuracy: 0.2639 - 164ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.0823 - val_accuracy: 0.2639 - 157ms/epoch - 17ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 6.6233 - val_accuracy: 0.2639 - 156ms/epoch - 17ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.7619 - val_accuracy: 0.3194 - 171ms/epoch - 19ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 5.3172 - val_accuracy: 0.2639 - 172ms/epoch - 19ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.4368 - val_accuracy: 0.2778 - 176ms/epoch - 20ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 6.2554 - val_accuracy: 0.2639 - 170ms/epoch - 19ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 6.8041 - val_accuracy: 0.1806 - 169ms/epoch - 19ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 7.9476 - val_accuracy: 0.3194 - 157ms/epoch - 17ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 6.0772 - val_accuracy: 0.2361 - 155ms/epoch - 17ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 8.0707 - val_accuracy: 0.2222 - 157ms/epoch - 17ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 9.8710 - val_accuracy: 0.2639 - 158ms/epoch - 18ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 8.9948 - val_accuracy: 0.2500 - 156ms/epoch - 17ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 10.4412 - val_accuracy: 0.2222 - 163ms/epoch - 18ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 11.5518 - val_accuracy: 0.2639 - 206ms/epoch - 23ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0286 - accuracy: 0.9931 - val_loss: 17.2108 - val_accuracy: 0.2222 - 210ms/epoch - 23ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0653 - accuracy: 0.9931 - val_loss: 10.2709 - val_accuracy: 0.2222 - 190ms/epoch - 21ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.2062 - accuracy: 0.9444 - val_loss: 10.7005 - val_accuracy: 0.2222 - 282ms/epoch - 31ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.1433 - accuracy: 0.9861 - val_loss: 12.6089 - val_accuracy: 0.2639 - 171ms/epoch - 19ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.1392 - accuracy: 0.9722 - val_loss: 9.9241 - val_accuracy: 0.2222 - 165ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0880 - accuracy: 0.9931 - val_loss: 9.9171 - val_accuracy: 0.2639 - 154ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0707 - accuracy: 0.9861 - val_loss: 13.5960 - val_accuracy: 0.2778 - 154ms/epoch - 17ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0389 - accuracy: 1.0000 - val_loss: 13.1992 - val_accuracy: 0.2222 - 150ms/epoch - 17ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0440 - accuracy: 0.9931 - val_loss: 7.6160 - val_accuracy: 0.2639 - 153ms/epoch - 17ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0335 - accuracy: 1.0000 - val_loss: 7.6317 - val_accuracy: 0.1944 - 151ms/epoch - 17ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 7.1867 - val_accuracy: 0.2361 - 182ms/epoch - 20ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 4.4509 - val_accuracy: 0.3194 - 215ms/epoch - 24ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 4.5993 - val_accuracy: 0.2639 - 186ms/epoch - 21ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.8403 - val_accuracy: 0.3333 - 224ms/epoch - 25ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 4.6924 - val_accuracy: 0.2361 - 177ms/epoch - 20ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.9441 - val_accuracy: 0.2778 - 181ms/epoch - 20ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.9947 - val_accuracy: 0.2639 - 183ms/epoch - 20ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.8135 - val_accuracy: 0.3194 - 158ms/epoch - 18ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.0095 - val_accuracy: 0.4583 - 153ms/epoch - 17ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1433 - val_accuracy: 0.2639 - 199ms/epoch - 22ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.2639 - 244ms/epoch - 27ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.4583 - 227ms/epoch - 25ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.5242 - val_accuracy: 0.4861 - 187ms/epoch - 21ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.9315 - val_accuracy: 0.2778 - 186ms/epoch - 21ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.1355 - val_accuracy: 0.2500 - 198ms/epoch - 22ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.0196 - val_accuracy: 0.2222 - 161ms/epoch - 18ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.9372 - val_accuracy: 0.3333 - 160ms/epoch - 18ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 5.0183 - val_accuracy: 0.2778 - 175ms/epoch - 19ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.4263 - val_accuracy: 0.4306 - 244ms/epoch - 27ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4554 - val_accuracy: 0.4722 - 160ms/epoch - 18ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.3611 - 166ms/epoch - 18ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.3140 - val_accuracy: 0.2778 - 219ms/epoch - 24ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6214 - val_accuracy: 0.2639 - 198ms/epoch - 22ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2129 - val_accuracy: 0.3194 - 188ms/epoch - 21ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.6543 - val_accuracy: 0.2778 - 218ms/epoch - 24ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0786 - val_accuracy: 0.3056 - 174ms/epoch - 19ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.7403 - val_accuracy: 0.2500 - 168ms/epoch - 19ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.62596\n",
      "9/9 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8616 - val_accuracy: 0.3472 - 172ms/epoch - 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# The config of ShallowConvNet Model training details\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f29a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal weights\n",
    "model.load_weights(\"./shallow model/checkpoint_SC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53a4f2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n",
      "Classification accuracy: 0.652778 \n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# make prediction on test set.\n",
    "###############################################################################\n",
    "\n",
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "242eda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./shallow model/checkpoint_SC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb44f173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'ShallowConv-Net'}, xlabel='Predicted label', ylabel='True label'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "\n",
    "names = ['hand left', 'hand right', 'feet', 'tongue']\n",
    "plt.figure(0)\n",
    "\n",
    "plot_confusion_matrix(Y_test.argmax(axis=-1), preds, np.array(names), title='ShallowConv-Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "001a08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model for Future Inferences\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"./shallow model/model_shallowConvNet.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./shallow model/model_shallowConvNet.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
