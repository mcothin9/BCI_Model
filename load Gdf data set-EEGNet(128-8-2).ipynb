{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a638ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e1e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "all_file_path = glob.glob('BCICIV 2a/*.gdf')\n",
    "print(len(all_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ddaf893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n"
     ]
    }
   ],
   "source": [
    "train_file_path = [i for i in all_file_path if 'T' in i.split('\\\\', 1)[-1]]\n",
    "eval_file_path = [i for i in all_file_path if 'E' in i.split('\\\\', 1)[-1]]\n",
    "print(len(train_file_path),len(eval_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db07729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the function of data generating and filterring\n",
    "def read_data(file_path):\n",
    "    data = mne.io.read_raw_gdf(file_path, preload = True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(0.5, 100, method='iir')\n",
    "    # Set EOG channel types\n",
    "    eog_channels = ['EOG-left', 'EOG-central', 'EOG-right']\n",
    "    for ch_name in eog_channels:\n",
    "        if ch_name in data.ch_names:\n",
    "            data.set_channel_types({ch_name: 'eog'})\n",
    "\n",
    "    # Pick EEG and EOG channels\n",
    "    picks = mne.pick_types(data.info, meg=False, eeg=True, eog=False, stim=False,\n",
    "                       exclude=[])\n",
    "    events, event_id = mne.events_from_annotations(data)\n",
    "    selected_event_labels = ['769', '770', '771', '772']\n",
    "    selected_event_id = {label: event_id[label] for label in selected_event_labels}\n",
    "\n",
    "    # Filter the events array\n",
    "    selected_events = events[np.isin(events[:, 2], list(selected_event_id.values()))]\n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(data, selected_events, selected_event_id, tmin = -0., tmax = 1, proj=False, \n",
    "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
    "    labels = epochs.events[:, -1]\n",
    "    # extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "    X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
    "    Y = labels\n",
    "    return X\n",
    "def read_labels(file_path):\n",
    "    data = mne.io.read_raw_gdf(file_path, preload = True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(0.5, 100, method='iir')\n",
    "    # Set EOG channel types\n",
    "    eog_channels = ['EOG-left', 'EOG-central', 'EOG-right']\n",
    "    for ch_name in eog_channels:\n",
    "        if ch_name in data.ch_names:\n",
    "            data.set_channel_types({ch_name: 'eog'})\n",
    "\n",
    "    # Pick EEG and EOG channels\n",
    "    picks = mne.pick_types(data.info, meg=False, eeg=True, eog=False, stim=False,\n",
    "                       exclude=[])\n",
    "    events, event_id = mne.events_from_annotations(data)\n",
    "    selected_event_labels = ['769', '770', '771', '772']\n",
    "    selected_event_id = {label: event_id[label] for label in selected_event_labels}\n",
    "\n",
    "    # Filter the events array\n",
    "    selected_events = events[np.isin(events[:, 2], list(selected_event_id.values()))]\n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(data, selected_events, selected_event_id, tmin = -0., tmax = 1, proj=False, \n",
    "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
    "    labels = epochs.events[:, -1]\n",
    "    # extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "    X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
    "    Y = labels\n",
    "    Y -= 6\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec1bbd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/mitchell/Downloads/Trained Models/BCICIV 2a/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchell/anaconda3/envs/bci_test/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 1e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 100.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from /Users/mitchell/Downloads/Trained Models/BCICIV 2a/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mitchell/anaconda3/envs/bci_test/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 1e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 100.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    }
   ],
   "source": [
    "X = read_data(train_file_path[0])\n",
    "Y = read_labels(train_file_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af3115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e853616",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, chans, samples = 1, 22, 251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba1882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 50/25/25 percent of the data to train/validate/test\n",
    "X_train      = X[0:144,]\n",
    "Y_train      = Y[0:144]\n",
    "X_validate   = X[144:216,]\n",
    "Y_validate   = Y[144:216]\n",
    "X_test       = X[216:,]\n",
    "Y_test       = Y[216:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b922a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 15:23:02.618585: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# convert labels to one-hot encodings.\n",
    "Y_train      = to_categorical(Y_train-1)\n",
    "Y_validate   = to_categorical(Y_validate-1)\n",
    "Y_test       = to_categorical(Y_test-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0bdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to NHWC (trials, channels, samples, kernels) format. Data \n",
    "# contains 22 channels and 251 time-points. Set the number of kernels to 1.\n",
    "X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_validate   = X_validate.reshape(X_validate.shape[0], chans, samples, kernels)\n",
    "X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ecdcd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (144, 22, 251, 1)\n",
      "[[[ 0.00718636]\n",
      "  [ 0.00910629]\n",
      "  [ 0.01217317]\n",
      "  ...\n",
      "  [-0.00546961]\n",
      "  [-0.005243  ]\n",
      "  [-0.00408977]]\n",
      "\n",
      " [[ 0.00182106]\n",
      "  [ 0.00303724]\n",
      "  [ 0.00355259]\n",
      "  ...\n",
      "  [-0.00215978]\n",
      "  [-0.00515362]\n",
      "  [-0.00557592]]\n",
      "\n",
      " [[ 0.00220968]\n",
      "  [ 0.004249  ]\n",
      "  [ 0.00623719]\n",
      "  ...\n",
      "  [-0.0064771 ]\n",
      "  [-0.006795  ]\n",
      "  [-0.00680417]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00065093]\n",
      "  [-0.00138428]\n",
      "  [-0.00151616]\n",
      "  ...\n",
      "  [ 0.00540202]\n",
      "  [ 0.00486136]\n",
      "  [ 0.001413  ]]\n",
      "\n",
      " [[ 0.00084465]\n",
      "  [-0.00178895]\n",
      "  [-0.00325722]\n",
      "  ...\n",
      "  [ 0.00542044]\n",
      "  [ 0.00592322]\n",
      "  [ 0.0026308 ]]\n",
      "\n",
      " [[ 0.00387408]\n",
      "  [ 0.00077742]\n",
      "  [ 0.00087902]\n",
      "  ...\n",
      "  [ 0.00820446]\n",
      "  [ 0.0104787 ]\n",
      "  [ 0.00535328]]]\n",
      "72 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train[0])\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415d4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from CNNModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8028711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 15:23:06.270669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# configure the EEGNet-8,2,16 model with kernel length of 128 samples (other \n",
    "# model configurations may do better, but this is a good starting point)\n",
    "model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples, \n",
    "               dropoutRate = 0.5, kernLength = 128, F1 = 8, D = 2, F2 = 16, \n",
    "               dropoutType = 'Dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f97352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model and set the optimizers\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbc48d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint_gdf.h5', verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b91485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
    "# the weights all to be 1\n",
    "class_weights = {0:1, 1:1, 2:1, 3:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d4675fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38609, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 1s - loss: 1.4633 - accuracy: 0.1944 - val_loss: 1.3861 - val_accuracy: 0.2917 - 1s/epoch - 113ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38609 to 1.38594, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.3729 - accuracy: 0.3264 - val_loss: 1.3859 - val_accuracy: 0.2917 - 366ms/epoch - 41ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38594 to 1.38587, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.3410 - accuracy: 0.3403 - val_loss: 1.3859 - val_accuracy: 0.2917 - 441ms/epoch - 49ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 1.38587 to 1.38567, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.2990 - accuracy: 0.4514 - val_loss: 1.3857 - val_accuracy: 0.2917 - 389ms/epoch - 43ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 1.38567 to 1.38547, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.2813 - accuracy: 0.4306 - val_loss: 1.3855 - val_accuracy: 0.2917 - 363ms/epoch - 40ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 1.38547 to 1.38524, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.2279 - accuracy: 0.5000 - val_loss: 1.3852 - val_accuracy: 0.2917 - 365ms/epoch - 41ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 1.38524 to 1.38494, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.2262 - accuracy: 0.5208 - val_loss: 1.3849 - val_accuracy: 0.2917 - 375ms/epoch - 42ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 1.38494 to 1.38449, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.2165 - accuracy: 0.5069 - val_loss: 1.3845 - val_accuracy: 0.2917 - 397ms/epoch - 44ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss improved from 1.38449 to 1.38428, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.1740 - accuracy: 0.5208 - val_loss: 1.3843 - val_accuracy: 0.2917 - 395ms/epoch - 44ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss improved from 1.38428 to 1.38388, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.1411 - accuracy: 0.5903 - val_loss: 1.3839 - val_accuracy: 0.2917 - 363ms/epoch - 40ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 1.38388 to 1.38314, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.1281 - accuracy: 0.6042 - val_loss: 1.3831 - val_accuracy: 0.2917 - 365ms/epoch - 41ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss improved from 1.38314 to 1.38258, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.1153 - accuracy: 0.6111 - val_loss: 1.3826 - val_accuracy: 0.2917 - 377ms/epoch - 42ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss improved from 1.38258 to 1.38207, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0875 - accuracy: 0.5833 - val_loss: 1.3821 - val_accuracy: 0.2917 - 402ms/epoch - 45ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss improved from 1.38207 to 1.38146, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0903 - accuracy: 0.6111 - val_loss: 1.3815 - val_accuracy: 0.2917 - 388ms/epoch - 43ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 1.38146 to 1.38090, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0913 - accuracy: 0.5556 - val_loss: 1.3809 - val_accuracy: 0.2917 - 361ms/epoch - 40ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss improved from 1.38090 to 1.38040, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.1029 - accuracy: 0.5694 - val_loss: 1.3804 - val_accuracy: 0.2917 - 368ms/epoch - 41ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss improved from 1.38040 to 1.38004, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0745 - accuracy: 0.6111 - val_loss: 1.3800 - val_accuracy: 0.2917 - 372ms/epoch - 41ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss improved from 1.38004 to 1.37939, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0269 - accuracy: 0.6250 - val_loss: 1.3794 - val_accuracy: 0.2917 - 399ms/epoch - 44ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 1.37939 to 1.37891, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0396 - accuracy: 0.6181 - val_loss: 1.3789 - val_accuracy: 0.2917 - 396ms/epoch - 44ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 1.37891 to 1.37846, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0300 - accuracy: 0.6736 - val_loss: 1.3785 - val_accuracy: 0.2917 - 365ms/epoch - 41ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss improved from 1.37846 to 1.37778, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0255 - accuracy: 0.6597 - val_loss: 1.3778 - val_accuracy: 0.2917 - 362ms/epoch - 40ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss improved from 1.37778 to 1.37725, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0052 - accuracy: 0.6528 - val_loss: 1.3772 - val_accuracy: 0.2917 - 374ms/epoch - 42ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 1.37725 to 1.37655, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0026 - accuracy: 0.6597 - val_loss: 1.3766 - val_accuracy: 0.2917 - 383ms/epoch - 43ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 1.37655 to 1.37603, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0071 - accuracy: 0.6181 - val_loss: 1.3760 - val_accuracy: 0.2917 - 454ms/epoch - 50ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss improved from 1.37603 to 1.37578, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0074 - accuracy: 0.6389 - val_loss: 1.3758 - val_accuracy: 0.2917 - 433ms/epoch - 48ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 1.37578 to 1.37541, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 1.0198 - accuracy: 0.5903 - val_loss: 1.3754 - val_accuracy: 0.2917 - 367ms/epoch - 41ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss improved from 1.37541 to 1.37465, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9654 - accuracy: 0.6875 - val_loss: 1.3747 - val_accuracy: 0.2917 - 364ms/epoch - 40ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss improved from 1.37465 to 1.37378, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9887 - accuracy: 0.6389 - val_loss: 1.3738 - val_accuracy: 0.2917 - 374ms/epoch - 42ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 1.37378 to 1.37279, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9542 - accuracy: 0.7083 - val_loss: 1.3728 - val_accuracy: 0.2917 - 388ms/epoch - 43ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 1.37279 to 1.37216, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9544 - accuracy: 0.6597 - val_loss: 1.3722 - val_accuracy: 0.2917 - 377ms/epoch - 42ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 1.37216 to 1.37192, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9544 - accuracy: 0.6736 - val_loss: 1.3719 - val_accuracy: 0.2917 - 361ms/epoch - 40ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss improved from 1.37192 to 1.37081, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9209 - accuracy: 0.6597 - val_loss: 1.3708 - val_accuracy: 0.2917 - 361ms/epoch - 40ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 1.37081 to 1.37002, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9682 - accuracy: 0.6667 - val_loss: 1.3700 - val_accuracy: 0.2917 - 374ms/epoch - 42ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss improved from 1.37002 to 1.36830, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9131 - accuracy: 0.7014 - val_loss: 1.3683 - val_accuracy: 0.2917 - 388ms/epoch - 43ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss improved from 1.36830 to 1.36754, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9316 - accuracy: 0.6944 - val_loss: 1.3675 - val_accuracy: 0.2917 - 380ms/epoch - 42ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.36754 to 1.36701, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9089 - accuracy: 0.6944 - val_loss: 1.3670 - val_accuracy: 0.2917 - 361ms/epoch - 40ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 1.36701 to 1.36516, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8589 - accuracy: 0.7639 - val_loss: 1.3652 - val_accuracy: 0.2917 - 361ms/epoch - 40ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 1.36516 to 1.36257, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8984 - accuracy: 0.6875 - val_loss: 1.3626 - val_accuracy: 0.2778 - 371ms/epoch - 41ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss improved from 1.36257 to 1.35869, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8986 - accuracy: 0.7153 - val_loss: 1.3587 - val_accuracy: 0.2917 - 392ms/epoch - 44ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss improved from 1.35869 to 1.35685, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.9036 - accuracy: 0.6736 - val_loss: 1.3568 - val_accuracy: 0.2778 - 386ms/epoch - 43ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss improved from 1.35685 to 1.35399, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8593 - accuracy: 0.7222 - val_loss: 1.3540 - val_accuracy: 0.2917 - 366ms/epoch - 41ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 1.35399 to 1.34986, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8276 - accuracy: 0.7639 - val_loss: 1.3499 - val_accuracy: 0.3056 - 453ms/epoch - 50ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss improved from 1.34986 to 1.34643, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 1s - loss: 0.8628 - accuracy: 0.7292 - val_loss: 1.3464 - val_accuracy: 0.3056 - 525ms/epoch - 58ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss improved from 1.34643 to 1.34136, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8387 - accuracy: 0.7569 - val_loss: 1.3414 - val_accuracy: 0.3194 - 484ms/epoch - 54ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss improved from 1.34136 to 1.33632, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8085 - accuracy: 0.7639 - val_loss: 1.3363 - val_accuracy: 0.3333 - 454ms/epoch - 50ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss improved from 1.33632 to 1.33255, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8095 - accuracy: 0.7569 - val_loss: 1.3326 - val_accuracy: 0.3333 - 374ms/epoch - 42ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss improved from 1.33255 to 1.32832, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 1s - loss: 0.8331 - accuracy: 0.7222 - val_loss: 1.3283 - val_accuracy: 0.3611 - 525ms/epoch - 58ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss improved from 1.32832 to 1.32378, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8188 - accuracy: 0.7500 - val_loss: 1.3238 - val_accuracy: 0.4028 - 470ms/epoch - 52ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss improved from 1.32378 to 1.32017, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8158 - accuracy: 0.7431 - val_loss: 1.3202 - val_accuracy: 0.3889 - 495ms/epoch - 55ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss improved from 1.32017 to 1.31250, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7709 - accuracy: 0.7917 - val_loss: 1.3125 - val_accuracy: 0.4583 - 412ms/epoch - 46ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss improved from 1.31250 to 1.30180, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8212 - accuracy: 0.7361 - val_loss: 1.3018 - val_accuracy: 0.5139 - 374ms/epoch - 42ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 1.30180 to 1.29689, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.8095 - accuracy: 0.7431 - val_loss: 1.2969 - val_accuracy: 0.5278 - 371ms/epoch - 41ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss improved from 1.29689 to 1.29315, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7530 - accuracy: 0.7917 - val_loss: 1.2932 - val_accuracy: 0.5139 - 397ms/epoch - 44ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss improved from 1.29315 to 1.28832, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7707 - accuracy: 0.7708 - val_loss: 1.2883 - val_accuracy: 0.5000 - 401ms/epoch - 45ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss improved from 1.28832 to 1.27803, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7681 - accuracy: 0.7778 - val_loss: 1.2780 - val_accuracy: 0.5000 - 367ms/epoch - 41ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss improved from 1.27803 to 1.26358, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7552 - accuracy: 0.7292 - val_loss: 1.2636 - val_accuracy: 0.5139 - 371ms/epoch - 41ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss improved from 1.26358 to 1.24866, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7757 - accuracy: 0.7917 - val_loss: 1.2487 - val_accuracy: 0.5278 - 370ms/epoch - 41ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss improved from 1.24866 to 1.23622, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7359 - accuracy: 0.7847 - val_loss: 1.2362 - val_accuracy: 0.5556 - 431ms/epoch - 48ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss improved from 1.23622 to 1.22196, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7500 - accuracy: 0.7639 - val_loss: 1.2220 - val_accuracy: 0.5556 - 394ms/epoch - 44ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss improved from 1.22196 to 1.21333, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7304 - accuracy: 0.8056 - val_loss: 1.2133 - val_accuracy: 0.5833 - 368ms/epoch - 41ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss improved from 1.21333 to 1.20070, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7685 - accuracy: 0.7778 - val_loss: 1.2007 - val_accuracy: 0.5694 - 364ms/epoch - 40ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss improved from 1.20070 to 1.19134, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7052 - accuracy: 0.8056 - val_loss: 1.1913 - val_accuracy: 0.5833 - 374ms/epoch - 42ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss improved from 1.19134 to 1.18266, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7162 - accuracy: 0.8194 - val_loss: 1.1827 - val_accuracy: 0.5833 - 406ms/epoch - 45ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss improved from 1.18266 to 1.17258, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7258 - accuracy: 0.8056 - val_loss: 1.1726 - val_accuracy: 0.6111 - 453ms/epoch - 50ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss improved from 1.17258 to 1.15322, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7170 - accuracy: 0.8194 - val_loss: 1.1532 - val_accuracy: 0.5972 - 430ms/epoch - 48ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss improved from 1.15322 to 1.13733, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.7083 - accuracy: 0.8264 - val_loss: 1.1373 - val_accuracy: 0.6111 - 367ms/epoch - 41ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss improved from 1.13733 to 1.13087, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6722 - accuracy: 0.7986 - val_loss: 1.1309 - val_accuracy: 0.6111 - 368ms/epoch - 41ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss improved from 1.13087 to 1.12911, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6760 - accuracy: 0.8264 - val_loss: 1.1291 - val_accuracy: 0.6111 - 390ms/epoch - 43ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss improved from 1.12911 to 1.11448, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6898 - accuracy: 0.7917 - val_loss: 1.1145 - val_accuracy: 0.5694 - 397ms/epoch - 44ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss improved from 1.11448 to 1.10041, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6820 - accuracy: 0.7778 - val_loss: 1.1004 - val_accuracy: 0.5556 - 385ms/epoch - 43ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss improved from 1.10041 to 1.08382, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6748 - accuracy: 0.8403 - val_loss: 1.0838 - val_accuracy: 0.6111 - 365ms/epoch - 41ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss improved from 1.08382 to 1.07881, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6603 - accuracy: 0.8194 - val_loss: 1.0788 - val_accuracy: 0.5972 - 366ms/epoch - 41ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss improved from 1.07881 to 1.06825, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6544 - accuracy: 0.8125 - val_loss: 1.0682 - val_accuracy: 0.5972 - 391ms/epoch - 43ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss improved from 1.06825 to 1.05758, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6640 - accuracy: 0.7778 - val_loss: 1.0576 - val_accuracy: 0.5694 - 393ms/epoch - 44ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss improved from 1.05758 to 1.05110, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6275 - accuracy: 0.8472 - val_loss: 1.0511 - val_accuracy: 0.5556 - 375ms/epoch - 42ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss improved from 1.05110 to 1.02857, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6419 - accuracy: 0.8750 - val_loss: 1.0286 - val_accuracy: 0.5833 - 369ms/epoch - 41ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss improved from 1.02857 to 1.02547, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6414 - accuracy: 0.8264 - val_loss: 1.0255 - val_accuracy: 0.5833 - 370ms/epoch - 41ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.02547\n",
      "9/9 - 0s - loss: 0.6385 - accuracy: 0.8056 - val_loss: 1.0297 - val_accuracy: 0.5972 - 356ms/epoch - 40ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss improved from 1.02547 to 1.02440, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6211 - accuracy: 0.8750 - val_loss: 1.0244 - val_accuracy: 0.5833 - 406ms/epoch - 45ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss improved from 1.02440 to 1.00564, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6436 - accuracy: 0.8125 - val_loss: 1.0056 - val_accuracy: 0.5972 - 384ms/epoch - 43ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss improved from 1.00564 to 0.99790, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6415 - accuracy: 0.8472 - val_loss: 0.9979 - val_accuracy: 0.5833 - 365ms/epoch - 41ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss improved from 0.99790 to 0.98504, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6589 - accuracy: 0.8125 - val_loss: 0.9850 - val_accuracy: 0.5972 - 368ms/epoch - 41ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss improved from 0.98504 to 0.98415, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6377 - accuracy: 0.8264 - val_loss: 0.9842 - val_accuracy: 0.5833 - 378ms/epoch - 42ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss improved from 0.98415 to 0.96218, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6062 - accuracy: 0.8542 - val_loss: 0.9622 - val_accuracy: 0.6111 - 392ms/epoch - 44ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss improved from 0.96218 to 0.95265, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6321 - accuracy: 0.8194 - val_loss: 0.9527 - val_accuracy: 0.5833 - 393ms/epoch - 44ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.95265\n",
      "9/9 - 0s - loss: 0.6245 - accuracy: 0.8194 - val_loss: 0.9580 - val_accuracy: 0.6111 - 335ms/epoch - 37ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.95265\n",
      "9/9 - 0s - loss: 0.6066 - accuracy: 0.8472 - val_loss: 0.9613 - val_accuracy: 0.6250 - 339ms/epoch - 38ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.95265\n",
      "9/9 - 0s - loss: 0.5870 - accuracy: 0.8750 - val_loss: 0.9573 - val_accuracy: 0.6111 - 342ms/epoch - 38ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.95265\n",
      "9/9 - 0s - loss: 0.5742 - accuracy: 0.8819 - val_loss: 0.9626 - val_accuracy: 0.6250 - 350ms/epoch - 39ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.95265\n",
      "9/9 - 0s - loss: 0.6308 - accuracy: 0.8194 - val_loss: 0.9610 - val_accuracy: 0.5833 - 361ms/epoch - 40ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss improved from 0.95265 to 0.94650, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.6055 - accuracy: 0.8472 - val_loss: 0.9465 - val_accuracy: 0.5972 - 386ms/epoch - 43ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss improved from 0.94650 to 0.93554, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5940 - accuracy: 0.8750 - val_loss: 0.9355 - val_accuracy: 0.5833 - 376ms/epoch - 42ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss improved from 0.93554 to 0.91935, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5762 - accuracy: 0.8333 - val_loss: 0.9194 - val_accuracy: 0.6250 - 366ms/epoch - 41ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss improved from 0.91935 to 0.91889, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5613 - accuracy: 0.8611 - val_loss: 0.9189 - val_accuracy: 0.6250 - 380ms/epoch - 42ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss improved from 0.91889 to 0.90766, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5855 - accuracy: 0.8611 - val_loss: 0.9077 - val_accuracy: 0.6667 - 378ms/epoch - 42ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.90766\n",
      "9/9 - 0s - loss: 0.5682 - accuracy: 0.8472 - val_loss: 0.9137 - val_accuracy: 0.6944 - 365ms/epoch - 41ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.90766\n",
      "9/9 - 0s - loss: 0.5609 - accuracy: 0.8889 - val_loss: 0.9255 - val_accuracy: 0.6667 - 346ms/epoch - 38ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.90766\n",
      "9/9 - 0s - loss: 0.5741 - accuracy: 0.8750 - val_loss: 0.9276 - val_accuracy: 0.6667 - 335ms/epoch - 37ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.90766\n",
      "9/9 - 0s - loss: 0.5593 - accuracy: 0.8819 - val_loss: 0.9172 - val_accuracy: 0.6667 - 338ms/epoch - 38ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.90766\n",
      "9/9 - 0s - loss: 0.5792 - accuracy: 0.8611 - val_loss: 0.9177 - val_accuracy: 0.6111 - 354ms/epoch - 39ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.90766\n",
      "9/9 - 0s - loss: 0.5522 - accuracy: 0.8472 - val_loss: 0.9336 - val_accuracy: 0.5833 - 369ms/epoch - 41ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss improved from 0.90766 to 0.90617, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5663 - accuracy: 0.8611 - val_loss: 0.9062 - val_accuracy: 0.6389 - 391ms/epoch - 43ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5472 - accuracy: 0.8542 - val_loss: 0.9165 - val_accuracy: 0.6250 - 338ms/epoch - 38ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5543 - accuracy: 0.8333 - val_loss: 0.9216 - val_accuracy: 0.6250 - 335ms/epoch - 37ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5655 - accuracy: 0.8681 - val_loss: 0.9192 - val_accuracy: 0.6667 - 351ms/epoch - 39ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5190 - accuracy: 0.8889 - val_loss: 0.9191 - val_accuracy: 0.6528 - 433ms/epoch - 48ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5579 - accuracy: 0.8542 - val_loss: 0.9196 - val_accuracy: 0.6528 - 407ms/epoch - 45ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5251 - accuracy: 0.8681 - val_loss: 0.9321 - val_accuracy: 0.7083 - 361ms/epoch - 40ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.4981 - accuracy: 0.8889 - val_loss: 0.9388 - val_accuracy: 0.6250 - 338ms/epoch - 38ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5450 - accuracy: 0.8542 - val_loss: 0.9181 - val_accuracy: 0.6528 - 346ms/epoch - 38ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5364 - accuracy: 0.9097 - val_loss: 0.9211 - val_accuracy: 0.6250 - 372ms/epoch - 41ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5275 - accuracy: 0.8819 - val_loss: 0.9132 - val_accuracy: 0.6806 - 360ms/epoch - 40ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5132 - accuracy: 0.8819 - val_loss: 0.9161 - val_accuracy: 0.6806 - 337ms/epoch - 37ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.4897 - accuracy: 0.8958 - val_loss: 0.9321 - val_accuracy: 0.6528 - 347ms/epoch - 39ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.90617\n",
      "9/9 - 0s - loss: 0.5209 - accuracy: 0.8681 - val_loss: 0.9185 - val_accuracy: 0.6111 - 349ms/epoch - 39ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss improved from 0.90617 to 0.89051, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5485 - accuracy: 0.8611 - val_loss: 0.8905 - val_accuracy: 0.6389 - 376ms/epoch - 42ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.89051\n",
      "9/9 - 0s - loss: 0.5599 - accuracy: 0.8542 - val_loss: 0.9033 - val_accuracy: 0.6389 - 352ms/epoch - 39ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss improved from 0.89051 to 0.88680, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5465 - accuracy: 0.8611 - val_loss: 0.8868 - val_accuracy: 0.6806 - 439ms/epoch - 49ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.5253 - accuracy: 0.8750 - val_loss: 0.8995 - val_accuracy: 0.6667 - 347ms/epoch - 39ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.5103 - accuracy: 0.8681 - val_loss: 0.8943 - val_accuracy: 0.6806 - 336ms/epoch - 37ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.4995 - accuracy: 0.8889 - val_loss: 0.9055 - val_accuracy: 0.6528 - 349ms/epoch - 39ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.5295 - accuracy: 0.8750 - val_loss: 0.8936 - val_accuracy: 0.6389 - 375ms/epoch - 42ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.5246 - accuracy: 0.8750 - val_loss: 0.8994 - val_accuracy: 0.6389 - 384ms/epoch - 43ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.4917 - accuracy: 0.9097 - val_loss: 0.9059 - val_accuracy: 0.6389 - 356ms/epoch - 40ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.88680\n",
      "9/9 - 0s - loss: 0.5332 - accuracy: 0.8681 - val_loss: 0.9079 - val_accuracy: 0.6667 - 384ms/epoch - 43ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss improved from 0.88680 to 0.87198, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.5122 - accuracy: 0.8750 - val_loss: 0.8720 - val_accuracy: 0.7083 - 369ms/epoch - 41ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.5280 - accuracy: 0.8472 - val_loss: 0.8844 - val_accuracy: 0.6944 - 359ms/epoch - 40ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.5294 - accuracy: 0.8611 - val_loss: 0.9073 - val_accuracy: 0.6667 - 407ms/epoch - 45ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4908 - accuracy: 0.9097 - val_loss: 0.8916 - val_accuracy: 0.7083 - 353ms/epoch - 39ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4931 - accuracy: 0.8681 - val_loss: 0.8730 - val_accuracy: 0.7083 - 338ms/epoch - 38ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.5113 - accuracy: 0.8819 - val_loss: 0.8821 - val_accuracy: 0.6528 - 340ms/epoch - 38ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.5196 - accuracy: 0.8542 - val_loss: 0.8907 - val_accuracy: 0.6389 - 342ms/epoch - 38ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4667 - accuracy: 0.9028 - val_loss: 0.9041 - val_accuracy: 0.6806 - 365ms/epoch - 41ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4879 - accuracy: 0.9028 - val_loss: 0.8935 - val_accuracy: 0.6528 - 364ms/epoch - 40ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.5045 - accuracy: 0.8750 - val_loss: 0.8815 - val_accuracy: 0.6667 - 337ms/epoch - 37ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4663 - accuracy: 0.8958 - val_loss: 0.8838 - val_accuracy: 0.6806 - 348ms/epoch - 39ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4802 - accuracy: 0.8750 - val_loss: 0.8907 - val_accuracy: 0.6806 - 339ms/epoch - 38ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.87198\n",
      "9/9 - 0s - loss: 0.4838 - accuracy: 0.8750 - val_loss: 0.8834 - val_accuracy: 0.6667 - 349ms/epoch - 39ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss improved from 0.87198 to 0.87077, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.4900 - accuracy: 0.8819 - val_loss: 0.8708 - val_accuracy: 0.6667 - 399ms/epoch - 44ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss improved from 0.87077 to 0.86069, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.4804 - accuracy: 0.8889 - val_loss: 0.8607 - val_accuracy: 0.6528 - 391ms/epoch - 43ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4910 - accuracy: 0.8889 - val_loss: 0.8695 - val_accuracy: 0.6806 - 338ms/epoch - 38ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4700 - accuracy: 0.9236 - val_loss: 0.8837 - val_accuracy: 0.6528 - 340ms/epoch - 38ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4440 - accuracy: 0.9236 - val_loss: 0.8856 - val_accuracy: 0.6667 - 343ms/epoch - 38ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4448 - accuracy: 0.8889 - val_loss: 0.8632 - val_accuracy: 0.6944 - 350ms/epoch - 39ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4488 - accuracy: 0.9167 - val_loss: 0.8666 - val_accuracy: 0.7083 - 379ms/epoch - 42ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4334 - accuracy: 0.9236 - val_loss: 0.8846 - val_accuracy: 0.6944 - 346ms/epoch - 38ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4336 - accuracy: 0.9028 - val_loss: 0.9064 - val_accuracy: 0.6528 - 335ms/epoch - 37ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4669 - accuracy: 0.8958 - val_loss: 0.8878 - val_accuracy: 0.6528 - 341ms/epoch - 38ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4816 - accuracy: 0.8681 - val_loss: 0.8741 - val_accuracy: 0.6389 - 345ms/epoch - 38ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4325 - accuracy: 0.9444 - val_loss: 0.8924 - val_accuracy: 0.6667 - 377ms/epoch - 42ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4579 - accuracy: 0.8958 - val_loss: 0.8993 - val_accuracy: 0.6250 - 440ms/epoch - 49ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4570 - accuracy: 0.8958 - val_loss: 0.8783 - val_accuracy: 0.6389 - 376ms/epoch - 42ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.86069\n",
      "9/9 - 0s - loss: 0.4251 - accuracy: 0.9097 - val_loss: 0.8816 - val_accuracy: 0.6528 - 340ms/epoch - 38ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss improved from 0.86069 to 0.85186, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.4282 - accuracy: 0.9097 - val_loss: 0.8519 - val_accuracy: 0.6806 - 365ms/epoch - 41ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.85186\n",
      "9/9 - 0s - loss: 0.4547 - accuracy: 0.8750 - val_loss: 0.8568 - val_accuracy: 0.6806 - 363ms/epoch - 40ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.85186\n",
      "9/9 - 0s - loss: 0.4169 - accuracy: 0.9236 - val_loss: 0.8869 - val_accuracy: 0.6806 - 367ms/epoch - 41ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.85186\n",
      "9/9 - 0s - loss: 0.4314 - accuracy: 0.8750 - val_loss: 0.8611 - val_accuracy: 0.7222 - 353ms/epoch - 39ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss improved from 0.85186 to 0.85139, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.4020 - accuracy: 0.9653 - val_loss: 0.8514 - val_accuracy: 0.7083 - 375ms/epoch - 42ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4503 - accuracy: 0.8819 - val_loss: 0.8576 - val_accuracy: 0.6389 - 336ms/epoch - 37ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4308 - accuracy: 0.9167 - val_loss: 0.8639 - val_accuracy: 0.7083 - 346ms/epoch - 38ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4669 - accuracy: 0.8611 - val_loss: 0.8669 - val_accuracy: 0.6667 - 340ms/epoch - 38ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4335 - accuracy: 0.9097 - val_loss: 0.8671 - val_accuracy: 0.6528 - 370ms/epoch - 41ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4297 - accuracy: 0.8958 - val_loss: 0.8787 - val_accuracy: 0.6806 - 358ms/epoch - 40ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4119 - accuracy: 0.9236 - val_loss: 0.8638 - val_accuracy: 0.6944 - 356ms/epoch - 40ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.85139\n",
      "9/9 - 0s - loss: 0.4248 - accuracy: 0.9028 - val_loss: 0.8627 - val_accuracy: 0.6944 - 362ms/epoch - 40ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss improved from 0.85139 to 0.84696, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.4297 - accuracy: 0.8819 - val_loss: 0.8470 - val_accuracy: 0.7083 - 390ms/epoch - 43ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4414 - accuracy: 0.8958 - val_loss: 0.8532 - val_accuracy: 0.6528 - 384ms/epoch - 43ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.3999 - accuracy: 0.9236 - val_loss: 0.8519 - val_accuracy: 0.7222 - 377ms/epoch - 42ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4300 - accuracy: 0.9028 - val_loss: 0.8496 - val_accuracy: 0.7083 - 349ms/epoch - 39ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.3923 - accuracy: 0.9375 - val_loss: 0.8698 - val_accuracy: 0.6944 - 348ms/epoch - 39ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4209 - accuracy: 0.9097 - val_loss: 0.8649 - val_accuracy: 0.6806 - 428ms/epoch - 48ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.3651 - accuracy: 0.9097 - val_loss: 0.8837 - val_accuracy: 0.6944 - 470ms/epoch - 52ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.84696\n",
      "9/9 - 1s - loss: 0.4006 - accuracy: 0.9097 - val_loss: 0.8831 - val_accuracy: 0.6528 - 501ms/epoch - 56ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.3916 - accuracy: 0.8819 - val_loss: 0.8652 - val_accuracy: 0.6806 - 412ms/epoch - 46ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4059 - accuracy: 0.9236 - val_loss: 0.8721 - val_accuracy: 0.7083 - 415ms/epoch - 46ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4179 - accuracy: 0.9236 - val_loss: 0.8816 - val_accuracy: 0.6667 - 407ms/epoch - 45ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.84696\n",
      "9/9 - 1s - loss: 0.4520 - accuracy: 0.8681 - val_loss: 0.8869 - val_accuracy: 0.6667 - 581ms/epoch - 65ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.84696\n",
      "9/9 - 1s - loss: 0.3576 - accuracy: 0.9444 - val_loss: 0.8664 - val_accuracy: 0.6944 - 512ms/epoch - 57ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4341 - accuracy: 0.8819 - val_loss: 0.8700 - val_accuracy: 0.6667 - 352ms/epoch - 39ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4205 - accuracy: 0.8889 - val_loss: 0.8519 - val_accuracy: 0.6944 - 354ms/epoch - 39ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4111 - accuracy: 0.9167 - val_loss: 0.8668 - val_accuracy: 0.6944 - 415ms/epoch - 46ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.3785 - accuracy: 0.9306 - val_loss: 0.8689 - val_accuracy: 0.7083 - 421ms/epoch - 47ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.84696\n",
      "9/9 - 0s - loss: 0.4049 - accuracy: 0.8958 - val_loss: 0.8744 - val_accuracy: 0.7222 - 339ms/epoch - 38ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss improved from 0.84696 to 0.84275, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.3782 - accuracy: 0.9028 - val_loss: 0.8427 - val_accuracy: 0.6806 - 381ms/epoch - 42ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.84275\n",
      "9/9 - 0s - loss: 0.3668 - accuracy: 0.9444 - val_loss: 0.8463 - val_accuracy: 0.6944 - 350ms/epoch - 39ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.84275\n",
      "9/9 - 0s - loss: 0.3975 - accuracy: 0.9167 - val_loss: 0.8769 - val_accuracy: 0.7083 - 371ms/epoch - 41ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.84275\n",
      "9/9 - 0s - loss: 0.3752 - accuracy: 0.9375 - val_loss: 0.8791 - val_accuracy: 0.6944 - 395ms/epoch - 44ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.84275\n",
      "9/9 - 0s - loss: 0.4135 - accuracy: 0.9167 - val_loss: 0.8619 - val_accuracy: 0.6806 - 383ms/epoch - 43ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.84275\n",
      "9/9 - 0s - loss: 0.3813 - accuracy: 0.9236 - val_loss: 0.8794 - val_accuracy: 0.6806 - 435ms/epoch - 48ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.84275\n",
      "9/9 - 0s - loss: 0.3825 - accuracy: 0.9236 - val_loss: 0.8729 - val_accuracy: 0.6528 - 410ms/epoch - 46ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.84275\n",
      "9/9 - 1s - loss: 0.4105 - accuracy: 0.8958 - val_loss: 0.8801 - val_accuracy: 0.6528 - 557ms/epoch - 62ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.84275\n",
      "9/9 - 1s - loss: 0.3925 - accuracy: 0.8958 - val_loss: 0.8763 - val_accuracy: 0.6806 - 537ms/epoch - 60ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss improved from 0.84275 to 0.83587, saving model to /tmp/checkpoint_gdf.h5\n",
      "9/9 - 0s - loss: 0.3316 - accuracy: 0.9653 - val_loss: 0.8359 - val_accuracy: 0.7083 - 475ms/epoch - 53ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.4110 - accuracy: 0.9236 - val_loss: 0.8435 - val_accuracy: 0.6806 - 450ms/epoch - 50ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3978 - accuracy: 0.8958 - val_loss: 0.8630 - val_accuracy: 0.6944 - 387ms/epoch - 43ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3557 - accuracy: 0.9375 - val_loss: 0.8836 - val_accuracy: 0.6944 - 398ms/epoch - 44ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3776 - accuracy: 0.8819 - val_loss: 0.8916 - val_accuracy: 0.6667 - 393ms/epoch - 44ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3971 - accuracy: 0.9097 - val_loss: 0.8686 - val_accuracy: 0.6806 - 412ms/epoch - 46ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3534 - accuracy: 0.9236 - val_loss: 0.8920 - val_accuracy: 0.6944 - 349ms/epoch - 39ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3635 - accuracy: 0.9167 - val_loss: 0.9073 - val_accuracy: 0.6667 - 384ms/epoch - 43ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3682 - accuracy: 0.9167 - val_loss: 0.9046 - val_accuracy: 0.6389 - 387ms/epoch - 43ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3925 - accuracy: 0.9097 - val_loss: 0.8602 - val_accuracy: 0.6806 - 371ms/epoch - 41ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3847 - accuracy: 0.8750 - val_loss: 0.8476 - val_accuracy: 0.6667 - 356ms/epoch - 40ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3741 - accuracy: 0.9306 - val_loss: 0.8582 - val_accuracy: 0.6667 - 355ms/epoch - 39ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3430 - accuracy: 0.9514 - val_loss: 0.8767 - val_accuracy: 0.6528 - 374ms/epoch - 42ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3543 - accuracy: 0.9306 - val_loss: 0.8963 - val_accuracy: 0.6944 - 396ms/epoch - 44ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3628 - accuracy: 0.9028 - val_loss: 0.8977 - val_accuracy: 0.6528 - 401ms/epoch - 45ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3767 - accuracy: 0.8889 - val_loss: 0.8828 - val_accuracy: 0.6528 - 352ms/epoch - 39ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3400 - accuracy: 0.9167 - val_loss: 0.8913 - val_accuracy: 0.6667 - 376ms/epoch - 42ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.4057 - accuracy: 0.8819 - val_loss: 0.9055 - val_accuracy: 0.6667 - 373ms/epoch - 41ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.83587\n",
      "9/9 - 1s - loss: 0.3617 - accuracy: 0.9375 - val_loss: 0.8806 - val_accuracy: 0.6806 - 510ms/epoch - 57ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.83587\n",
      "9/9 - 1s - loss: 0.3394 - accuracy: 0.9236 - val_loss: 0.8788 - val_accuracy: 0.6389 - 575ms/epoch - 64ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3542 - accuracy: 0.9306 - val_loss: 0.8817 - val_accuracy: 0.6806 - 436ms/epoch - 48ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3305 - accuracy: 0.9722 - val_loss: 0.8644 - val_accuracy: 0.6667 - 447ms/epoch - 50ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3752 - accuracy: 0.9028 - val_loss: 0.8727 - val_accuracy: 0.6667 - 419ms/epoch - 47ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3331 - accuracy: 0.9444 - val_loss: 0.8687 - val_accuracy: 0.6667 - 377ms/epoch - 42ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3488 - accuracy: 0.9097 - val_loss: 0.8696 - val_accuracy: 0.6806 - 340ms/epoch - 38ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3045 - accuracy: 0.9444 - val_loss: 0.8603 - val_accuracy: 0.6528 - 357ms/epoch - 40ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3942 - accuracy: 0.8819 - val_loss: 0.8585 - val_accuracy: 0.6806 - 351ms/epoch - 39ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3295 - accuracy: 0.9583 - val_loss: 0.8780 - val_accuracy: 0.7083 - 409ms/epoch - 45ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3855 - accuracy: 0.9167 - val_loss: 0.8679 - val_accuracy: 0.6944 - 422ms/epoch - 47ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3366 - accuracy: 0.9167 - val_loss: 0.8924 - val_accuracy: 0.6806 - 363ms/epoch - 40ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3543 - accuracy: 0.9097 - val_loss: 0.9155 - val_accuracy: 0.6667 - 401ms/epoch - 45ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3722 - accuracy: 0.9167 - val_loss: 0.9165 - val_accuracy: 0.6806 - 374ms/epoch - 42ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3396 - accuracy: 0.9514 - val_loss: 0.8761 - val_accuracy: 0.6667 - 386ms/epoch - 43ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3560 - accuracy: 0.9306 - val_loss: 0.8580 - val_accuracy: 0.6667 - 395ms/epoch - 44ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3564 - accuracy: 0.9375 - val_loss: 0.8547 - val_accuracy: 0.6667 - 370ms/epoch - 41ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3409 - accuracy: 0.9375 - val_loss: 0.8481 - val_accuracy: 0.6667 - 350ms/epoch - 39ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3187 - accuracy: 0.9444 - val_loss: 0.9009 - val_accuracy: 0.6667 - 342ms/epoch - 38ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3338 - accuracy: 0.9375 - val_loss: 0.8972 - val_accuracy: 0.6528 - 394ms/epoch - 44ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3059 - accuracy: 0.9514 - val_loss: 0.8873 - val_accuracy: 0.6667 - 427ms/epoch - 47ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3488 - accuracy: 0.9375 - val_loss: 0.8864 - val_accuracy: 0.6667 - 387ms/epoch - 43ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3469 - accuracy: 0.9306 - val_loss: 0.8845 - val_accuracy: 0.6667 - 352ms/epoch - 39ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3445 - accuracy: 0.9167 - val_loss: 0.8777 - val_accuracy: 0.6667 - 335ms/epoch - 37ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3130 - accuracy: 0.9167 - val_loss: 0.8973 - val_accuracy: 0.6667 - 346ms/epoch - 38ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2878 - accuracy: 0.9375 - val_loss: 0.8624 - val_accuracy: 0.6528 - 341ms/epoch - 38ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3440 - accuracy: 0.9167 - val_loss: 0.8712 - val_accuracy: 0.6528 - 366ms/epoch - 41ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3177 - accuracy: 0.9514 - val_loss: 0.8548 - val_accuracy: 0.6528 - 353ms/epoch - 39ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3290 - accuracy: 0.9375 - val_loss: 0.8624 - val_accuracy: 0.6806 - 350ms/epoch - 39ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2656 - accuracy: 0.9653 - val_loss: 0.8649 - val_accuracy: 0.6389 - 363ms/epoch - 40ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3088 - accuracy: 0.9583 - val_loss: 0.8875 - val_accuracy: 0.6528 - 359ms/epoch - 40ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2833 - accuracy: 0.9444 - val_loss: 0.8875 - val_accuracy: 0.6528 - 385ms/epoch - 43ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3272 - accuracy: 0.9167 - val_loss: 0.8588 - val_accuracy: 0.6389 - 371ms/epoch - 41ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3401 - accuracy: 0.9444 - val_loss: 0.8849 - val_accuracy: 0.6250 - 363ms/epoch - 40ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3234 - accuracy: 0.9514 - val_loss: 0.9112 - val_accuracy: 0.6528 - 410ms/epoch - 46ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3260 - accuracy: 0.9097 - val_loss: 0.9216 - val_accuracy: 0.6389 - 389ms/epoch - 43ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3342 - accuracy: 0.9097 - val_loss: 0.9296 - val_accuracy: 0.6111 - 413ms/epoch - 46ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3308 - accuracy: 0.9236 - val_loss: 0.9094 - val_accuracy: 0.6250 - 363ms/epoch - 40ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3051 - accuracy: 0.9375 - val_loss: 0.8956 - val_accuracy: 0.6250 - 343ms/epoch - 38ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2908 - accuracy: 0.9583 - val_loss: 0.8757 - val_accuracy: 0.6250 - 340ms/epoch - 38ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3287 - accuracy: 0.9514 - val_loss: 0.8924 - val_accuracy: 0.6806 - 361ms/epoch - 40ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3066 - accuracy: 0.9375 - val_loss: 0.8940 - val_accuracy: 0.6806 - 354ms/epoch - 39ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3222 - accuracy: 0.9375 - val_loss: 0.8768 - val_accuracy: 0.6250 - 401ms/epoch - 45ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2783 - accuracy: 0.9792 - val_loss: 0.8869 - val_accuracy: 0.6250 - 380ms/epoch - 42ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3059 - accuracy: 0.9306 - val_loss: 0.9016 - val_accuracy: 0.6528 - 397ms/epoch - 44ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3379 - accuracy: 0.9306 - val_loss: 0.9137 - val_accuracy: 0.6250 - 398ms/epoch - 44ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2973 - accuracy: 0.9236 - val_loss: 0.9016 - val_accuracy: 0.6528 - 379ms/epoch - 42ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3146 - accuracy: 0.9167 - val_loss: 0.9035 - val_accuracy: 0.6389 - 434ms/epoch - 48ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2885 - accuracy: 0.9375 - val_loss: 0.9234 - val_accuracy: 0.6528 - 375ms/epoch - 42ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2836 - accuracy: 0.9583 - val_loss: 0.8976 - val_accuracy: 0.6944 - 345ms/epoch - 38ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3175 - accuracy: 0.9444 - val_loss: 0.9043 - val_accuracy: 0.6389 - 343ms/epoch - 38ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3122 - accuracy: 0.9167 - val_loss: 0.8994 - val_accuracy: 0.6528 - 345ms/epoch - 38ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3301 - accuracy: 0.9306 - val_loss: 0.8725 - val_accuracy: 0.6667 - 402ms/epoch - 45ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3278 - accuracy: 0.9028 - val_loss: 0.8705 - val_accuracy: 0.6528 - 416ms/epoch - 46ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3028 - accuracy: 0.9236 - val_loss: 0.8746 - val_accuracy: 0.6528 - 356ms/epoch - 40ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3057 - accuracy: 0.9375 - val_loss: 0.9019 - val_accuracy: 0.6111 - 352ms/epoch - 39ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2753 - accuracy: 0.9653 - val_loss: 0.9294 - val_accuracy: 0.6111 - 362ms/epoch - 40ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3053 - accuracy: 0.9444 - val_loss: 0.9209 - val_accuracy: 0.6389 - 413ms/epoch - 46ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3000 - accuracy: 0.9583 - val_loss: 0.9053 - val_accuracy: 0.6389 - 375ms/epoch - 42ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2921 - accuracy: 0.9514 - val_loss: 0.9201 - val_accuracy: 0.6667 - 347ms/epoch - 39ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3350 - accuracy: 0.8889 - val_loss: 0.8911 - val_accuracy: 0.6944 - 374ms/epoch - 42ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3098 - accuracy: 0.9167 - val_loss: 0.8882 - val_accuracy: 0.6944 - 363ms/epoch - 40ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2787 - accuracy: 0.9514 - val_loss: 0.9002 - val_accuracy: 0.6528 - 381ms/epoch - 42ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3092 - accuracy: 0.9375 - val_loss: 0.9076 - val_accuracy: 0.6528 - 467ms/epoch - 52ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.83587\n",
      "9/9 - 1s - loss: 0.3271 - accuracy: 0.9306 - val_loss: 0.9389 - val_accuracy: 0.6944 - 642ms/epoch - 71ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3471 - accuracy: 0.9028 - val_loss: 0.9225 - val_accuracy: 0.6528 - 428ms/epoch - 48ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3213 - accuracy: 0.9097 - val_loss: 0.8778 - val_accuracy: 0.6389 - 370ms/epoch - 41ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3151 - accuracy: 0.9028 - val_loss: 0.8824 - val_accuracy: 0.6250 - 418ms/epoch - 46ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2992 - accuracy: 0.9375 - val_loss: 0.8834 - val_accuracy: 0.6667 - 378ms/epoch - 42ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2498 - accuracy: 0.9583 - val_loss: 0.8727 - val_accuracy: 0.6667 - 355ms/epoch - 39ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3073 - accuracy: 0.9167 - val_loss: 0.8974 - val_accuracy: 0.6667 - 346ms/epoch - 38ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2690 - accuracy: 0.9514 - val_loss: 0.8900 - val_accuracy: 0.6667 - 368ms/epoch - 41ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3186 - accuracy: 0.9028 - val_loss: 0.9116 - val_accuracy: 0.6667 - 391ms/epoch - 43ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.83587\n",
      "9/9 - 1s - loss: 0.2928 - accuracy: 0.9583 - val_loss: 0.9069 - val_accuracy: 0.6528 - 527ms/epoch - 59ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.83587\n",
      "9/9 - 1s - loss: 0.3199 - accuracy: 0.9097 - val_loss: 0.8895 - val_accuracy: 0.6806 - 533ms/epoch - 59ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2928 - accuracy: 0.9514 - val_loss: 0.8662 - val_accuracy: 0.6528 - 365ms/epoch - 41ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2616 - accuracy: 0.9653 - val_loss: 0.8476 - val_accuracy: 0.6667 - 367ms/epoch - 41ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2585 - accuracy: 0.9722 - val_loss: 0.8822 - val_accuracy: 0.6944 - 381ms/epoch - 42ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3028 - accuracy: 0.9306 - val_loss: 0.9008 - val_accuracy: 0.6944 - 375ms/epoch - 42ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2794 - accuracy: 0.9514 - val_loss: 0.9027 - val_accuracy: 0.6667 - 343ms/epoch - 38ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2580 - accuracy: 0.9583 - val_loss: 0.8972 - val_accuracy: 0.6667 - 335ms/epoch - 37ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2659 - accuracy: 0.9514 - val_loss: 0.8661 - val_accuracy: 0.6250 - 341ms/epoch - 38ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3207 - accuracy: 0.9444 - val_loss: 0.8424 - val_accuracy: 0.6528 - 401ms/epoch - 45ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2481 - accuracy: 0.9514 - val_loss: 0.8849 - val_accuracy: 0.6528 - 404ms/epoch - 45ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2871 - accuracy: 0.9444 - val_loss: 0.9282 - val_accuracy: 0.6250 - 366ms/epoch - 41ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2879 - accuracy: 0.9375 - val_loss: 0.9605 - val_accuracy: 0.6528 - 358ms/epoch - 40ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2559 - accuracy: 0.9514 - val_loss: 0.9431 - val_accuracy: 0.6111 - 348ms/epoch - 39ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2272 - accuracy: 0.9792 - val_loss: 0.9180 - val_accuracy: 0.6250 - 382ms/epoch - 42ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.2595 - accuracy: 0.9514 - val_loss: 0.9137 - val_accuracy: 0.6389 - 391ms/epoch - 43ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.83587\n",
      "9/9 - 0s - loss: 0.3073 - accuracy: 0.9306 - val_loss: 0.9197 - val_accuracy: 0.6250 - 347ms/epoch - 39ms/step\n"
     ]
    }
   ],
   "source": [
    "# The config of EEGNet Model training details\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a4f2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step\n",
      "Classification accuracy: 0.611111 \n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# make prediction on test set.\n",
    "###############################################################################\n",
    "\n",
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48e6cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Saving the model for Future Inferences\n",
    "\n",
    "model_json = model.to_json()\n",
    "\n",
    "path = \"./EEG model\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "with open(\"./EEG model/model_EEGNet.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./EEG model/model_EEGNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb44f173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'EEGNet-8,2'}, xlabel='Predicted label', ylabel='True label'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrices for both classifiers\n",
    "names        = ['left hand', 'right hand', 'both feet', 'tongue']\n",
    "plt.figure(0)\n",
    "plot_confusion_matrix(preds, Y_test.argmax(axis = -1), names, title = 'EEGNet-8,2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
